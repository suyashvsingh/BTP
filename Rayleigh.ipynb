{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Rayleigh$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.signal as ss\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "N = 10000  # Number of Monte Carlo iterations\n",
    "S = 4096  # Sampled length\n",
    "a1, a2 = 0.8, 0.2  # Power allocations\n",
    "Pf = 0.1  # False-alarm probability\n",
    "env_SNRs_dB = np.arange(\n",
    "    -25, 6, 1\n",
    ")  # Range of environmental SNR values to iterate through\n",
    "transmitter_power = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists to store results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pds = []  # List to store detection probabilities\n",
    "TPRs = []  # List to store true positive rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env_SNR_dB in env_SNRs_dB:\n",
    "    # Convert SNR from dB to linear scale\n",
    "    env_SNR_linear = transmitter_power * 10 ** (env_SNR_dB / 10)\n",
    "\n",
    "    # Noise standard deviation based on environmental SNR\n",
    "    N0 = np.sqrt(1 / (2 * env_SNR_linear))\n",
    "\n",
    "    # Threshold for AND joint user decision\n",
    "    lambda_AND = (np.sqrt(-np.log(Pf) / (2 * S))) * (N0**2)\n",
    "\n",
    "    # Monte Carlo simulation\n",
    "    total_transmit = 0\n",
    "    successful_detection = 0\n",
    "    false_alarm_count = 0\n",
    "\n",
    "    F = []\n",
    "\n",
    "    for _ in range(N):\n",
    "        # Random cyclic delays\n",
    "        d1, d2 = np.random.randint(1, S, 2)\n",
    "\n",
    "        # Complex normal channel coefficients\n",
    "        h1 = np.random.normal(0, np.sqrt(0.5)) + 1j * np.random.normal(0, np.sqrt(0.5))\n",
    "        h2 = np.random.normal(0, np.sqrt(0.5)) + 1j * np.random.normal(0, np.sqrt(0.5))\n",
    "\n",
    "        # 50% chance that BS1 will transmit signal\n",
    "        transmit = np.random.rand() < 0.5\n",
    "\n",
    "        if transmit:\n",
    "            total_transmit += 1\n",
    "\n",
    "            # Generating signals for user 1 and user 2\n",
    "            x1_n = np.random.randn(S)\n",
    "            x2_n = np.random.randn(S)\n",
    "\n",
    "            # Combining signals to produce t1 and t2\n",
    "            t1_n = a1 * x1_n + a2 * x2_n\n",
    "            t2_n = a1 * np.roll(x1_n, d1) + a2 * np.roll(x2_n, d2)\n",
    "\n",
    "            # Rayleigh distributed complex normal noise\n",
    "            noise_std_dev = N0 * np.sqrt(1 / 2)\n",
    "            noise = noise_std_dev * (np.random.randn(S) + 1j * np.random.randn(S))\n",
    "\n",
    "            # Final sent signal\n",
    "            r_n = h1 * t1_n + h2 * t2_n + noise\n",
    "\n",
    "            # Cyclic correlation processing\n",
    "            F_delta1 = np.abs(np.sum(r_n * np.conj(np.roll(r_n, d1)))) / S\n",
    "            F_delta2 = np.abs(np.sum(r_n * np.conj(np.roll(r_n, d2)))) / S\n",
    "\n",
    "            F.append({\"F1\": F_delta1, \"F2\": F_delta2, \"transmit\": 1})\n",
    "\n",
    "            # Decision\n",
    "            if F_delta1 > lambda_AND and F_delta2 > lambda_AND:\n",
    "                successful_detection += 1\n",
    "\n",
    "        if not transmit:\n",
    "            # Generating noise only\n",
    "            noise_std_dev = N0 * np.sqrt(1 / 2)\n",
    "            noise = noise_std_dev * (np.random.randn(S) + 1j * np.random.randn(S))\n",
    "            r_n = noise\n",
    "\n",
    "            # Cyclic correlation processing\n",
    "            F_delta1 = np.abs(np.sum(r_n * np.conj(np.roll(r_n, d1)))) / S\n",
    "            F_delta2 = np.abs(np.sum(r_n * np.conj(np.roll(r_n, d2)))) / S\n",
    "\n",
    "            F.append({\"F1\": F_delta1, \"F2\": F_delta2, \"transmit\": 0})\n",
    "\n",
    "            # Decision\n",
    "            if F_delta1 > lambda_AND and F_delta2 > lambda_AND:\n",
    "                false_alarm_count += 1\n",
    "\n",
    "    # Probability of detection\n",
    "    Pd = successful_detection / total_transmit if total_transmit > 0 else 0\n",
    "    Pds.append(Pd)\n",
    "\n",
    "    # Convert F to DataFrame\n",
    "    F = pd.DataFrame(F)\n",
    "    X = F[[\"F1\", \"F2\"]]\n",
    "    y = F[\"transmit\"]\n",
    "\n",
    "    # Normalize the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "    # Divide the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_normalized, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Classifier\n",
    "    clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    # Train the Classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Define the desired FPR\n",
    "    desired_fpr = 0.1\n",
    "\n",
    "    # ROC curve plotting\n",
    "    y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Create an interpolation function using the FPR and TPR values\n",
    "    interp_tpr = interp1d(fpr, tpr)\n",
    "\n",
    "    # Define a new set of FPR values for the interpolated curve\n",
    "    new_fpr = np.linspace(0, 1, 1000)\n",
    "\n",
    "    # Use the interpolation function to find the TPR for the new FPR values\n",
    "    new_tpr = interp_tpr(new_fpr)\n",
    "\n",
    "    # TPR at desired FPR\n",
    "    tpr = interp_tpr(desired_fpr)\n",
    "    TPRs.append(tpr)\n",
    "\n",
    "    print(f\"SNR: {env_SNR_dB} dB Probability of detection: {Pd} fTPR at {desired_fpr} FPR: {tpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert lists to numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pds = np.array(Pds)\n",
    "TPRs = np.array(TPRs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Probability of detection vs Environmental SNR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Smooth the graph of Pds\n",
    "Pds_smooth = savgol_filter(Pds, window_length=5, polyorder=3)\n",
    "TPRs_smooth = savgol_filter(TPRs, window_length=5, polyorder=3)\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(-25, 5)\n",
    "\n",
    "# Plot the smoothed Probability of Detection vs. Environmental SNR\n",
    "plt.plot(env_SNRs_dB, Pds_smooth, marker=\"o\", label=\"Without ML\")\n",
    "\n",
    "# Plot the interpolated TPR at FPR = 0.1\n",
    "plt.plot(env_SNRs_dB, TPRs_smooth, marker=\"o\", color=\"red\", label=\"Using ML\")\n",
    "\n",
    "plt.title(\"Probability of Detection vs. Environmental SNR\")\n",
    "plt.xlabel(\"Environmental SNR (dB)\")\n",
    "plt.ylabel(\"Probability of Detection / TPR at FPR = 0.1\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
